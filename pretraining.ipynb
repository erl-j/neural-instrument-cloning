{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_NSYNTH=False\n",
    "#INSTRUMENT_FAMILY=\"**_WHITHOUT_SAX\"\n",
    "INSTRUMENT_FAMILY=\"Saxophone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_NSYNTH:\n",
    "    tfds.load(\"nsynth/gansynth_subset.f0_and_loudness\",split=\"train\", try_gcs=False,download=True) \n",
    "    trn_data_provider = data.CustomNSynthTfds(data_dir=\"/root/tensorflow_datasets/\",split=\"train\")\n",
    "    tfds.load(\"nsynth/gansynth_subset.f0_and_loudness\",split=\"valid\", try_gcs=False,download=True) \n",
    "    val_data_provider = data.CustomNSynthTfds(data_dir=\"/root/tensorflow_datasets/\",split=\"valid\")\n",
    "    def crepe_is_certain(x):\n",
    "        is_playing = tf.cast(x[\"loudness_db\"]>-100.0,dtype=tf.float32)\n",
    "        average_certainty=tf.reduce_sum(x[\"f0_confidence\"]*is_playing)/tf.reduce_sum(is_playing)\n",
    "        return average_certainty\n",
    "    def preprocess_dataset(dataset):\n",
    "        if INSTRUMENT_FAMILY!=\"all\":\n",
    "            dataset=dataset.filter(lambda x: x[\"instrument_family\"]==INSTRUMENT_FAMILY)\n",
    "        return dataset\n",
    "    trn_dataset = preprocess_dataset(trn_data_provider.get_dataset())\n",
    "    val_dataset = preprocess_dataset(val_data_provider.get_dataset())\n",
    "\n",
    "else:\n",
    "    \n",
    "    trn_path=f\"datasets/AIR/tfr/dev/{INSTRUMENT_FAMILY}/*\"\n",
    "    val_path=f\"datasets/AIR/tfr/tst/{INSTRUMENT_FAMILY}/*\"\n",
    "    \n",
    "    if INSTRUMENT_FAMILY==\"**_WHITHOUT_SAX\":\n",
    "        print(\"without_sax\")\n",
    "        trn_path=f\"datasets/AIRnoSax/tfr/dev/**/*\"\n",
    "        val_path=f\"datasets/AIRnoSax/tfr/tst/**/*\"\n",
    "    \n",
    "    trn_data_provider=data.MultiTFRecordProvider(trn_path,sample_rate=SAMPLE_RATE)\n",
    "    val_data_provider=data.MultiTFRecordProvider(val_path,sample_rate=SAMPLE_RATE)\n",
    "    trn_dataset= trn_data_provider.get_dataset()\n",
    "    val_dataset=val_data_provider.get_dataset(shuffle=False)\n",
    "    \n",
    "# remove some samples if number of recordings greater than model capacity\n",
    "trn_dataset = trn_dataset.filter(lambda x: int(x[\"instrument_idx\"])<N_INSTRUMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path=f\"checkpoints/48k_{'bidir' if BIDIRECTIONAL else 'unidir'}_z{Z_SIZE}_conv_family_{INSTRUMENT_FAMILY}{'_f0c' if USE_F0_CONFIDENCE else ''}\"\n",
    "training_savedir=f\"./artefacts/training/{INSTRUMENT_FAMILY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'replica_2/multi_instrument_autoencoder/processor_group/harmonic/zeros_like_1' defined at (most recent call last):\n    File \"/usr/lib/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/models/model.py\", line 54, in __call__\n      outputs = super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/workspace/neural-instrument-cloning/shared_model.py\", line 76, in call\n      return super().call(batch,training=training)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/models/autoencoder.py\", line 62, in call\n      pg_out = self.processor_group(features, return_outputs_dict=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/processors.py\", line 127, in call\n      controls = self.get_controls(inputs, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/processors.py\", line 147, in get_controls\n      return super().call(inputs, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/dags.py\", line 132, in call\n      return self.run_dag(inputs, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/gin/config.py\", line 238, in gin_wrapper\n      not_found = object()\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/dags.py\", line 156, in run_dag\n      for node in self.dag:\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/dags.py\", line 172, in run_dag\n      if is_processor(module):\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/dags.py\", line 174, in run_dag\n      module_outputs = module(*inputs, return_outputs_dict=True, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/processors.py\", line 65, in call\n      signal = self.get_signal(**controls)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/synths.py\", line 142, in get_signal\n      signal = core.harmonic_synthesis(\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/core.py\", line 927, in harmonic_synthesis\n      audio = oscillator_bank(frequency_envelopes,\n    File \"/usr/local/lib/python3.8/dist-packages/gin/config.py\", line 238, in gin_wrapper\n      not_found = object()\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/core.py\", line 828, in oscillator_bank\n      amplitude_envelopes = remove_above_nyquist(frequency_envelopes,\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/core.py\", line 790, in remove_above_nyquist\n      amplitude_envelopes = tf.where(\nNode: 'replica_2/multi_instrument_autoencoder/processor_group/harmonic/zeros_like_1'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor of shape [2,192000,192] and type float\n\t [[{{node replica_2/multi_instrument_autoencoder/processor_group/harmonic/zeros_like_1}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference___call___38576]\n  In call to configurable 'train' (<function train at 0x7fd6c412f040>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/workspace/neural-instrument-cloning/Generate_results.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=5'>6</a>\u001b[0m     model\u001b[39m.\u001b[39mset_is_shared_trainable(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=6'>7</a>\u001b[0m     trainer\u001b[39m=\u001b[39mddsp\u001b[39m.\u001b[39mtraining\u001b[39m.\u001b[39mtrainers\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=7'>8</a>\u001b[0m                    model,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=8'>9</a>\u001b[0m                    strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=12'>13</a>\u001b[0m                    lr_decay_rate\u001b[39m=\u001b[39m\u001b[39m0.98\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=13'>14</a>\u001b[0m                    grad_clip_norm\u001b[39m=\u001b[39m\u001b[39m100000.0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=15'>16</a>\u001b[0m ddsp\u001b[39m.\u001b[39;49mtraining\u001b[39m.\u001b[39;49mtrain_util\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=16'>17</a>\u001b[0m           trn_data_provider,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=17'>18</a>\u001b[0m           trainer,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=18'>19</a>\u001b[0m           batch_size\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=19'>20</a>\u001b[0m           num_steps\u001b[39m=\u001b[39;49m\u001b[39m1000000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=20'>21</a>\u001b[0m           steps_per_summary\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=21'>22</a>\u001b[0m           steps_per_save\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=22'>23</a>\u001b[0m           save_dir\u001b[39m=\u001b[39;49mtraining_savedir,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=23'>24</a>\u001b[0m           restore_dir\u001b[39m=\u001b[39;49mtraining_savedir,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=24'>25</a>\u001b[0m           early_stop_loss_value\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e6a6f6e615f6e69635f696d61676535222c2273657474696e6773223a7b22686f7374223a227373683a2f2f64656570737065656368227d7d/workspace/neural-instrument-cloning/Generate_results.ipynb#ch0000005vscode-remote?line=25'>26</a>\u001b[0m           report_loss_to_hypertune\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/gin/config.py?line=1602'>1603</a>\u001b[0m scope_info \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m in scope \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(scope_str) \u001b[39mif\u001b[39;00m scope_str \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/gin/config.py?line=1603'>1604</a>\u001b[0m err_str \u001b[39m=\u001b[39m err_str\u001b[39m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/gin/config.py?line=1604'>1605</a>\u001b[0m utils\u001b[39m.\u001b[39;49maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/gin/utils.py?line=38'>39</a>\u001b[0m proxy \u001b[39m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/gin/utils.py?line=39'>40</a>\u001b[0m ExceptionProxy\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(exception)\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/gin/utils.py?line=40'>41</a>\u001b[0m \u001b[39mraise\u001b[39;00m proxy\u001b[39m.\u001b[39mwith_traceback(exception\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/gin/config.py?line=1578'>1579</a>\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/gin/config.py?line=1580'>1581</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/gin/config.py?line=1581'>1582</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/gin/config.py?line=1582'>1583</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/gin/config.py?line=1583'>1584</a>\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py:261\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data_provider, trainer, batch_size, num_steps, steps_per_summary, steps_per_save, save_dir, restore_dir, early_stop_loss_value, report_loss_to_hypertune)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py?line=257'>258</a>\u001b[0m dataset_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(dataset)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py?line=259'>260</a>\u001b[0m \u001b[39m# Build model, easiest to just run forward pass.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py?line=260'>261</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mbuild(\u001b[39mnext\u001b[39;49m(dataset_iter))\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py?line=262'>263</a>\u001b[0m \u001b[39m# Load latest checkpoint if one exists in load directory.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py?line=263'>264</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py:143\u001b[0m, in \u001b[0;36mTrainer.build\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py?line=140'>141</a>\u001b[0m \u001b[39m\"\"\"Build the model by running a distributed batch through it.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py?line=141'>142</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mBuilding the model...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py?line=142'>143</a>\u001b[0m _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(tf\u001b[39m.\u001b[39;49mfunction(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m), batch)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py?line=143'>144</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py:138\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py?line=135'>136</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py?line=136'>137</a>\u001b[0m   \u001b[39m\"\"\"Distribute and run function on processors.\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py?line=137'>138</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mrun(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=1306'>1307</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=1307'>1308</a>\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=1308'>1309</a>\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=1309'>1310</a>\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=1310'>1311</a>\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=1311'>1312</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=2885'>2886</a>\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=2886'>2887</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py?line=2887'>2888</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:676\u001b[0m, in \u001b[0;36mMirroredExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_strategy.py?line=674'>675</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_strategy.py?line=675'>676</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m mirrored_run\u001b[39m.\u001b[39;49mcall_for_each_replica(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_strategy.py?line=676'>677</a>\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_container_strategy(), fn, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py:82\u001b[0m, in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=77'>78</a>\u001b[0m     wrapped \u001b[39m=\u001b[39m fn\u001b[39m.\u001b[39m_clone(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=78'>79</a>\u001b[0m         python_function\u001b[39m=\u001b[39mfunctools\u001b[39m.\u001b[39mpartial(call_for_each_replica, strategy,\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=79'>80</a>\u001b[0m                                           fn\u001b[39m.\u001b[39mpython_function))\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=80'>81</a>\u001b[0m     _cfer_fn_cache[strategy][fn] \u001b[39m=\u001b[39m wrapped\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=81'>82</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped(args, kwargs)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=83'>84</a>\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=84'>85</a>\u001b[0m   logging\u001b[39m.\u001b[39mlog_first_n(\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=85'>86</a>\u001b[0m       logging\u001b[39m.\u001b[39mWARN, \u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m eagerly has significant \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=86'>87</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39moverhead currently. We will be working on improving \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=89'>90</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`run` inside a tf.function to get \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py?line=90'>91</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mthe best performance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m strategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'replica_2/multi_instrument_autoencoder/processor_group/harmonic/zeros_like_1' defined at (most recent call last):\n    File \"/usr/lib/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/models/model.py\", line 54, in __call__\n      outputs = super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/workspace/neural-instrument-cloning/shared_model.py\", line 76, in call\n      return super().call(batch,training=training)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/models/autoencoder.py\", line 62, in call\n      pg_out = self.processor_group(features, return_outputs_dict=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/processors.py\", line 127, in call\n      controls = self.get_controls(inputs, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/processors.py\", line 147, in get_controls\n      return super().call(inputs, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/dags.py\", line 132, in call\n      return self.run_dag(inputs, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/gin/config.py\", line 238, in gin_wrapper\n      not_found = object()\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/dags.py\", line 156, in run_dag\n      for node in self.dag:\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/dags.py\", line 172, in run_dag\n      if is_processor(module):\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/dags.py\", line 174, in run_dag\n      module_outputs = module(*inputs, return_outputs_dict=True, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/processors.py\", line 65, in call\n      signal = self.get_signal(**controls)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/synths.py\", line 142, in get_signal\n      signal = core.harmonic_synthesis(\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/core.py\", line 927, in harmonic_synthesis\n      audio = oscillator_bank(frequency_envelopes,\n    File \"/usr/local/lib/python3.8/dist-packages/gin/config.py\", line 238, in gin_wrapper\n      not_found = object()\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/core.py\", line 828, in oscillator_bank\n      amplitude_envelopes = remove_above_nyquist(frequency_envelopes,\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/core.py\", line 790, in remove_above_nyquist\n      amplitude_envelopes = tf.where(\nNode: 'replica_2/multi_instrument_autoencoder/processor_group/harmonic/zeros_like_1'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor of shape [2,192000,192] and type float\n\t [[{{node replica_2/multi_instrument_autoencoder/processor_group/harmonic/zeros_like_1}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference___call___38576]\n  In call to configurable 'train' (<function train at 0x7fd6c412f040>)"
     ]
    }
   ],
   "source": [
    "# ddsp style training\n",
    "\n",
    "\n",
    "strategy =  tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "\n",
    "with strategy.scope():\n",
    "    model=shared_model.get_model(SAMPLE_RATE,CLIP_S,FT_FRAME_RATE,Z_SIZE,N_INSTRUMENTS,IR_DURATION,BIDIRECTIONAL,USE_F0_CONFIDENCE,N_HARMONICS,N_NOISE_MAGNITUDES,losses=[spectral_loss])\n",
    "    model.set_is_shared_trainable(True)\n",
    "    trainer=ddsp.training.trainers.Trainer(\n",
    "                model,\n",
    "                strategy,\n",
    "                checkpoints_to_keep=10,\n",
    "                lr_decay_steps=10000,\n",
    "                learning_rate=1e-4,\n",
    "                lr_decay_rate=0.98,\n",
    "                grad_clip_norm=100000.0)\n",
    "\n",
    "ddsp.training.train_util.train(\n",
    "        trn_data_provider,\n",
    "        trainer,\n",
    "        batch_size=6,\n",
    "        num_steps=1000000,\n",
    "        steps_per_summary=1000,\n",
    "        steps_per_save=1000,\n",
    "        save_dir=training_savedir,\n",
    "        restore_dir=training_savedir,\n",
    "        early_stop_loss_value=None,\n",
    "        report_loss_to_hypertune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute training loss across dataset\n",
    "\n",
    "if False:\n",
    "\n",
    "    BATCH_SIZE=1\n",
    "    batched_trn_dataset=trn_dataset.shuffle(10000).batch(BATCH_SIZE,drop_remainder=True)\n",
    "\n",
    "    # 1e-4 was good for saxophone (got us to 4.7-ish in 20 hours our so)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "    e=0\n",
    "\n",
    "    batch_counter=0\n",
    "    epoch_loss=0   \n",
    "    for batch in batched_trn_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            model.set_is_shared_trainable(True)\n",
    "            output=model(batch)\n",
    "            loss_value=spectral_loss(batch[\"audio\"],output[\"audio_synth\"])\n",
    "            gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "            epoch_loss+=loss_value.numpy()\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            batch_counter+=1\n",
    "            \n",
    "    result_dict[\"trn_loss\"]=[epoch_loss/batch_counter]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "slow instrument cloning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
