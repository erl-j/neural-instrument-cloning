{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3kBReFZb1eKk"
   },
   "outputs": [],
   "source": [
    "# imports and utils\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import ddsp.training\n",
    "_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "from IPython.display import Audio, display\n",
    "from livelossplot import PlotLosses\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import data\n",
    "\n",
    "# define constants\n",
    "N_SAMPLES=16000*4\n",
    "SAMPLE_RATE=16000\n",
    "SEED=1\n",
    "\n",
    "tf.random.set_seed(\n",
    "    SEED\n",
    ")\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "# define some utilis\n",
    "def play(audio):\n",
    "  display(Audio(audio,rate=SAMPLE_RATE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "USE_NSYNTH=False\n",
    "if USE_NSYNTH:\n",
    "    \n",
    "    class CustomNSynthTfds(ddsp.training.data.TfdsProvider):\n",
    "      \"\"\"Parses features in the TFDS NSynth dataset.\n",
    "      Unlike the default Nsynth data provider, this class keeps the the nsynth instrument metadata.\n",
    "\n",
    "      If running on Cloud, it is recommended you set `data_dir` to\n",
    "      'gs://tfds-data/datasets' to avoid unnecessary downloads.\n",
    "      \"\"\"\n",
    "\n",
    "      def __init__(self,\n",
    "                   name='nsynth/gansynth_subset.f0_and_loudness:2.3.3',\n",
    "                   split='train',\n",
    "                   data_dir='gs://tfds-data/datasets',\n",
    "                   sample_rate=16000,\n",
    "                   frame_rate=250,\n",
    "                   include_note_labels=True):\n",
    "        \"\"\"TfdsProvider constructor.\n",
    "        Args:\n",
    "          name: TFDS dataset name (with optional config and version).\n",
    "          split: Dataset split to use of the TFDS dataset.\n",
    "          data_dir: The directory to read the prepared NSynth dataset from. Defaults\n",
    "            to the public TFDS GCS bucket.\n",
    "          sample_rate: Sample rate of audio in the dataset.\n",
    "          frame_rate: Frame rate of features in the dataset.\n",
    "          include_note_labels: Return dataset without note-level labels\n",
    "            (pitch, instrument).\n",
    "        \"\"\"\n",
    "        self._include_note_labels = include_note_labels\n",
    "\n",
    "        super().__init__(name, split, data_dir, sample_rate, frame_rate)\n",
    "\n",
    "      def get_dataset(self, shuffle=True):\n",
    "        \"\"\"Returns dataset with slight restructuring of feature dictionary.\"\"\"\n",
    "        def preprocess_ex(ex):\n",
    "          ex_out = {\n",
    "              'audio':\n",
    "                  ex['audio'],\n",
    "              'f0_hz':\n",
    "                  ex['f0']['hz'],\n",
    "              'f0_confidence':\n",
    "                  ex['f0']['confidence'],\n",
    "              'loudness_db':\n",
    "                  ex['loudness']['db'],\n",
    "          }\n",
    "          if self._include_note_labels:\n",
    "            ex_out.update({\n",
    "                'pitch':\n",
    "                    ex['pitch'],\n",
    "                'velocity':\n",
    "                    ex['velocity'],\n",
    "                'instrument_source':\n",
    "                    ex['instrument']['source'],\n",
    "                'instrument_family':\n",
    "                    ex['instrument']['family'],\n",
    "                'instrument':\n",
    "                    ex['instrument']['label'],\n",
    "            })\n",
    "          return ex_out\n",
    "\n",
    "        dataset = super().get_dataset(shuffle)\n",
    "        dataset = dataset.map(preprocess_ex, num_parallel_calls=_AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    tfds.load(\"nsynth/gansynth_subset.f0_and_loudness\",split=\"train\", try_gcs=False,download=True) \n",
    "    trn_data_provider = CustomNSynthTfds(data_dir=\"/root/tensorflow_datasets/\",split=\"train\")\n",
    "\n",
    "    tfds.load(\"nsynth/gansynth_subset.f0_and_loudness\",split=\"valid\", try_gcs=False,download=True) \n",
    "    val_data_provider = CustomNSynthTfds(data_dir=\"/root/tensorflow_datasets/\",split=\"valid\")\n",
    "    \n",
    "    # take a batch of flute sounds\n",
    "    #dataset = data_provider.get_dataset()\n",
    "\n",
    "    # take only acoustic sounds\n",
    "    #dataset=dataset.filter(lambda x: x[\"instrument_source\"]==0)\n",
    "\n",
    "    # take only flute sounds\n",
    "    #dataset=dataset.filter(lambda x: x[\"instrument_family\"]==2)\n",
    "\n",
    "    # flutes\n",
    "    # 2965 samples\n",
    "    # 36 instruments\n",
    "    # 5 velocities \n",
    "    # 61 pitches\n",
    "\n",
    "    #test_batch=next(iter(dataset.batch(4))) \n",
    "\n",
    "    #play(tf.reshape(test_batch[\"audio\"],(-1)))\n",
    "\n",
    "    # TODO: CLEAN UP DATASET. REMOVE WHERE CREPE IS UNCERTAIN.\n",
    "\n",
    "    def crepe_is_certain(x):\n",
    "        is_playing = tf.cast(x[\"loudness_db\"]>-100.0,dtype=tf.float32)\n",
    "        average_certainty=tf.reduce_sum(x[\"f0_confidence\"]*is_playing)/tf.reduce_sum(is_playing)\n",
    "        return average_certainty\n",
    "\n",
    "    '''\n",
    "    for s in range(1):\n",
    "\n",
    "        print(\"###\")\n",
    "\n",
    "        sample = next(iter(dataset))\n",
    "        play(sample[\"audio\"])\n",
    "\n",
    "        print(crepe_is_certain(sample))\n",
    "\n",
    "        plt.plot(sample[\"loudness_db\"])\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(sample[\"f0_hz\"])\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(sample[\"f0_confidence\"])\n",
    "        plt.show()\n",
    "\n",
    "    '''\n",
    "\n",
    "    INSTRUMENT_FAMILY=2\n",
    "\n",
    "    def preprocess_dataset(dataset):\n",
    "        if INSTRUMENT_FAMILY!=\"all\":\n",
    "            dataset=dataset.filter(lambda x: x[\"instrument_family\"]==INSTRUMENT_FAMILY)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    trn_dataset = preprocess_dataset(trn_data_provider.get_dataset())\n",
    "    val_dataset = preprocess_dataset(val_data_provider.get_dataset())\n",
    "\n",
    "    # take only flute sounds\n",
    "\n",
    "\n",
    "else:\n",
    "    INSTRUMENT_FAMILY=\"solos-violin-clean\"\n",
    "    \n",
    "    trn_data_provider=data.MultiTFRecordProvider(f\"datasets/{INSTRUMENT_FAMILY}/tfr/trn/*\")\n",
    "    val_data_provider=data.MultiTFRecordProvider(f\"datasets/{INSTRUMENT_FAMILY}/tfr/val/*\")\n",
    "    \n",
    "    trn_dataset= trn_data_provider.get_dataset()\n",
    "    val_dataset=val_data_provider.get_dataset()\n",
    "    \n",
    "    def preprocess_dataset(dataset):\n",
    "        dataset=dataset.filter(lambda x: not tf.math.is_nan(x[\"audio\"]).any())\n",
    "        return dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Kj83Q3YrDEeT"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "N_NOISE_MAGNITUDES=64\n",
    "N_HARMONICS=64\n",
    "\n",
    "\n",
    "class CustomReverb(ddsp.processors.Processor):\n",
    "\n",
    "    def __init__(self,name='reverb'):\n",
    "        \"\"\"Takes neural network outputs directly as the impulse response.\n",
    "        Args:\n",
    "          trainable: Learn the impulse_response as a single variable for the entire\n",
    "            dataset.\n",
    "          reverb_length: Length of the impulse response. Only used if\n",
    "            trainable=True.\n",
    "          add_dry: Add dry signal to reverberated signal on output.\n",
    "          name: Name of processor module.\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "    \n",
    "    def get_controls(self, audio, ir=None):\n",
    "        \"\"\"Convert decoder outputs into ir response.\n",
    "        Args:\n",
    "          audio: Dry audio. 2-D Tensor of shape [batch, n_samples].\n",
    "          ir: 3-D Tensor of shape [batch, ir_size, 1] or 2D Tensor of shape\n",
    "            [batch, ir_size].\n",
    "        Returns:\n",
    "          controls: Dictionary of effect controls.\n",
    "        \"\"\"\n",
    "        return {'audio': audio, 'ir': ir}\n",
    "\n",
    "    def get_signal(self, audio, ir):\n",
    "        \"\"\"Apply impulse response.\n",
    "        Args:\n",
    "          audio: Dry audio, 2-D Tensor of shape [batch, n_samples].\n",
    "          ir: 3-D Tensor of shape [batch, ir_size, 1] or 2D Tensor of shape\n",
    "            [batch, ir_size].\n",
    "        Returns:\n",
    "          tensor of shape [batch, n_samples]\n",
    "        \"\"\"\n",
    "        wet = ddsp.core.fft_convolve(audio, ir, padding='same', delay_compensation=0)\n",
    "        return wet\n",
    "\n",
    "class LGD(ddsp.training.models.Model):\n",
    "\n",
    "    def __init__(self, n_out,  rnn_channels=256, rnn_type='gru', ch=512, layers_per_stack=0, name=None):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        def stack():\n",
    "            return ddsp.training.nn.FcStack(ch, layers_per_stack)\n",
    "\n",
    "        self.input_keys = [\"f0_hz\", \"ld_scaled\"]\n",
    "\n",
    "        self.n_out = n_out\n",
    "        self.input_stacks = [stack() for k in self.input_keys]\n",
    "\n",
    "        self.rnn = ddsp.training.nn.Rnn(rnn_channels, rnn_type)\n",
    "        self.out_stack = stack()\n",
    "        self.dense_out = ddsp.training.nn.Fc(self.n_out)\n",
    "\n",
    "    def call(self, conditioning):\n",
    "\n",
    "        instrument_representation = conditioning[\"z\"]\n",
    "\n",
    "        feature_len = conditioning[\"f0_scaled\"].shape[1]\n",
    "\n",
    "        instrument_representation = tf.repeat(\n",
    "            instrument_representation[:, None, ...], feature_len, axis=1)\n",
    "\n",
    "        inputs = [conditioning[k] for k in self.input_keys]\n",
    "\n",
    "        inputs = [stack(x) for stack, x in zip(self.input_stacks, inputs)]\n",
    "\n",
    "        x = tf.concat(inputs, axis=(-1))\n",
    "        x = tf.concat([x, instrument_representation], axis=2)\n",
    "        x = self.rnn(x)\n",
    "        x = tf.concat((inputs + [x]), axis=(-1))\n",
    "        x = self.out_stack(x)\n",
    "        out = self.dense_out(x)\n",
    "        \n",
    "        \n",
    "        loudness=out[:,:,-1:]\n",
    "        noise_magnitudes = out[:,:,:N_NOISE_MAGNITUDES]\n",
    "        harmonic_distribution = out[:,:,-N_HARMONICS:-1]\n",
    "            \n",
    "        return {\"amps\":loudness,\"harmonic_distribution\":harmonic_distribution,\"magnitudes\":noise_magnitudes}\n",
    "    \n",
    "preprocessor=ddsp.training.preprocessing.F0LoudnessPreprocessor()\n",
    "decoder = LGD(n_out=N_NOISE_MAGNITUDES+N_HARMONICS+1)\n",
    "harmonic_synth = ddsp.synths.Harmonic(\n",
    "    n_samples=N_SAMPLES, sample_rate=SAMPLE_RATE, name='harmonic')\n",
    "\n",
    "filtered_noise = ddsp.synths.FilteredNoise(\n",
    "    n_samples=N_SAMPLES, window_size=0, initial_bias=-10.0, name='noise')\n",
    "reverb = ddsp.effects.Reverb(name=\"reverb\",trainable=False)\n",
    "add = ddsp.processors.Add(name='add')\n",
    "\n",
    "dag = [\n",
    "  (harmonic_synth, ['amps', 'harmonic_distribution', 'f0_hz']),\n",
    "  (filtered_noise, ['magnitudes']),\n",
    "  (add, ['harmonic/signal', 'noise/signal']),\n",
    "  (reverb, [\"add/signal\",\"ir\"])\n",
    "]\n",
    "\n",
    "processor_group=ddsp.processors.ProcessorGroup(dag=dag)\n",
    "\n",
    "spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
    "                                              mag_weight=1.0,\n",
    "                                              logmag_weight=1.0)\n",
    "\n",
    "\n",
    "class MultiInstrumentAutoencoder(ddsp.training.models.autoencoder.Autoencoder):\n",
    "    def __init__(self,\n",
    "               preprocessor=None,\n",
    "               encoder=None,\n",
    "               decoder=None,\n",
    "               processor_group=None,\n",
    "               losses=None,\n",
    "               n_instruments=None,\n",
    "               z_size=None,\n",
    "               ir_size=None,\n",
    "               **kwargs):\n",
    "        super().__init__(preprocessor,encoder,decoder,processor_group,losses,**kwargs)\n",
    "        \n",
    "        self.n_instruments=n_instruments\n",
    "        self.instrument_z = tf.Variable(tf.random.normal([n_instruments,z_size]))\n",
    "        self.instrument_ir = tf.Variable(tf.concat([tf.ones([n_instruments,1]),tf.zeros([n_instruments,ir_size-1])],axis=-1))\n",
    "        self.instrument_id2idx={}\n",
    "        \n",
    "    def call(self, batch, training=True):\n",
    "        instrument_idxs=[]\n",
    " \n",
    "        for sample_index in range(batch[\"instrument\"].shape[0]):\n",
    "          instrument_id=str(batch[\"instrument\"][sample_index])\n",
    "          if instrument_id not in self.instrument_id2idx:\n",
    "              self.instrument_id2idx[instrument_id]=len(self.instrument_id2idx.keys())\n",
    "          instrument_idxs.append(int(self.instrument_id2idx[instrument_id]))\n",
    "  \n",
    "        with tf.GradientTape() as tape:\n",
    "          batch[\"z\"]=tf.tanh(tf.gather(self.instrument_z,instrument_idxs))\n",
    "          batch[\"ir\"]=tf.tanh(tf.gather(self.instrument_ir,instrument_idxs))     \n",
    "        return super().call(batch,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wJUeq9Kmwbga",
    "outputId": "d27f1547-a061-4bf7-d3d6-f5715199fb3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "Z_SIZE=256\n",
    "\n",
    "N_INSTRUMENTS=1050\n",
    "\n",
    "IR_SIZE=int(SAMPLE_RATE*1.0)\n",
    "\n",
    "plotlosses = PlotLosses()\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "def train_step(inputs):\n",
    "     \n",
    "    with tf.GradientTape() as tape:\n",
    "    \n",
    "        a = time.time()\n",
    "\n",
    "        output=ae(inputs,training=False)\n",
    "\n",
    "        loss_value=spectral_loss(inputs[\"audio\"],output['audio_synth'])\n",
    "\n",
    "        gradients = tape.gradient(loss_value, [*ae.trainable_variables])\n",
    "\n",
    "        #grad_is_nan=False\n",
    "        #for g in gradients:\n",
    "        #    grad_is_nan=grad_is_nan or tf.math.reduce_any(tf.math.is_nan(g))\n",
    "        \n",
    "\n",
    "        # if not grad_is_nan:\n",
    "        #     optimizer.apply_gradients(zip(gradients, [*ae.trainable_variables]))\n",
    "        \n",
    "    return loss_value\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses=strategy.run(train_step,args=(dataset_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM,per_replica_losses,axis=None)\n",
    "\n",
    "with strategy.scope():\n",
    "    ae = MultiInstrumentAutoencoder(preprocessor=preprocessor,decoder=decoder,processor_group=processor_group,n_instruments=N_INSTRUMENTS,z_size=Z_SIZE,ir_size=IR_SIZE) \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "\n",
    "\n",
    "BATCH_SIZE=16\n",
    "\n",
    "batched_trn_dataset= trn_dataset.shuffle(10000).batch(BATCH_SIZE*len(tf.config.list_physical_devices('GPU')),drop_remainder=True)\n",
    "batched_dist_trn_dataset = strategy.experimental_distribute_dataset(batched_trn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint\n",
      "couldn't load checkpoint\n",
      "16\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "INFO:tensorflow:Error reported to Coordinator: in user code:\n",
      "\n",
      "    <ipython-input-4-b7517a22445b>:17 train_step  *\n",
      "        output=ae(inputs,training=False)\n",
      "    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/model.py:54 __call__  *\n",
      "        outputs = super().__call__(*args, **kwargs)\n",
      "    <ipython-input-3-371f5ca9fabc>:142 call  *\n",
      "        return super().call(batch,training=False)\n",
      "    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/autoencoder.py:59 call  *\n",
      "        features.update(self.decoder(features, training=training))\n",
      "    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/model.py:54 __call__  *\n",
      "        outputs = super().__call__(*args, **kwargs)\n",
      "    <ipython-input-3-371f5ca9fabc>:76 call  *\n",
      "        x = self.rnn(x)\n",
      "    /usr/local/lib/python3.6/dist-packages/ddsp/training/nn.py:804 call  *\n",
      "        return self.rnn(x)\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py:659 __call__  **\n",
      "        return super(RNN, self).__call__(inputs, **kwargs)\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py:1037 __call__\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:444 call\n",
      "        inputs, initial_state, training, mask, row_lengths)\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:493 _defun_gru_call\n",
      "        'kernel': _read_variable_value(self.cell.kernel),\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:1759 _read_variable_value\n",
      "        return v.read_value()\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/values.py:763 read_value\n",
      "        with ds_context.enter_or_assert_strategy(self._distribute_strategy):\n",
      "    /usr/lib/python3.6/contextlib.py:81 __enter__\n",
      "        return next(self.gen)\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py:334 enter_or_assert_strategy\n",
      "        _assert_strategy(strategy)\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py:367 _assert_strategy\n",
      "        (current_strategy, strategy))\n",
      "\n",
      "    RuntimeError: Mixing different tf.distribute.Strategy objects: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f18142b26d8> is not <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f19a956bd68>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 346, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 695, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "RuntimeError: in user code:\n",
      "\n",
      "    <ipython-input-4-b7517a22445b>:17 train_step  *\n",
      "        output=ae(inputs,training=False)\n",
      "    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/model.py:54 __call__  *\n",
      "        outputs = super().__call__(*args, **kwargs)\n",
      "    <ipython-input-3-371f5ca9fabc>:142 call  *\n",
      "        return super().call(batch,training=False)\n",
      "    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/autoencoder.py:59 call  *\n",
      "        features.update(self.decoder(features, training=training))\n",
      "    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/model.py:54 __call__  *\n",
      "        outputs = super().__call__(*args, **kwargs)\n",
      "    <ipython-input-3-371f5ca9fabc>:76 call  *\n",
      "        x = self.rnn(x)\n",
      "    /usr/local/lib/python3.6/dist-packages/ddsp/training/nn.py:804 call  *\n",
      "        return self.rnn(x)\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py:659 __call__  **\n",
      "        return super(RNN, self).__call__(inputs, **kwargs)\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py:1037 __call__\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:444 call\n",
      "        inputs, initial_state, training, mask, row_lengths)\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:493 _defun_gru_call\n",
      "        'kernel': _read_variable_value(self.cell.kernel),\n",
      "    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:1759 _read_variable_value\n",
      "        return v.read_value()\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/values.py:763 read_value\n",
      "        with ds_context.enter_or_assert_strategy(self._distribute_strategy):\n",
      "    /usr/lib/python3.6/contextlib.py:81 __enter__\n",
      "        return next(self.gen)\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py:334 enter_or_assert_strategy\n",
      "        _assert_strategy(strategy)\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py:367 _assert_strategy\n",
      "        (current_strategy, strategy))\n",
      "\n",
      "    RuntimeError: Mixing different tf.distribute.Strategy objects: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f18142b26d8> is not <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f19a956bd68>\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "in user code:\n\n    <ipython-input-4-b7517a22445b>:36 distributed_train_step  *\n        per_replica_losses=strategy.run(train_step,args=(dataset_inputs,))\n    <ipython-input-4-b7517a22445b>:17 train_step  *\n        output=ae(inputs,training=False)\n    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/model.py:54 __call__  *\n        outputs = super().__call__(*args, **kwargs)\n    <ipython-input-3-371f5ca9fabc>:142 call  *\n        return super().call(batch,training=False)\n    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/autoencoder.py:59 call  *\n        features.update(self.decoder(features, training=training))\n    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/model.py:54 __call__  *\n        outputs = super().__call__(*args, **kwargs)\n    <ipython-input-3-371f5ca9fabc>:76 call  *\n        x = self.rnn(x)\n    /usr/local/lib/python3.6/dist-packages/ddsp/training/nn.py:804 call  *\n        return self.rnn(x)\n    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py:659 __call__  **\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:444 call\n        inputs, initial_state, training, mask, row_lengths)\n    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:493 _defun_gru_call\n        'kernel': _read_variable_value(self.cell.kernel),\n    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:1759 _read_variable_value\n        return v.read_value()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/values.py:763 read_value\n        with ds_context.enter_or_assert_strategy(self._distribute_strategy):\n    /usr/lib/python3.6/contextlib.py:81 __enter__\n        return next(self.gen)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py:334 enter_or_assert_strategy\n        _assert_strategy(strategy)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py:367 _assert_strategy\n        (current_strategy, strategy))\n\n    RuntimeError: Mixing different tf.distribute.Strategy objects: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f18142b26d8> is not <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f19a956bd68>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0280fc499267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mepoch_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatched_dist_trn_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mit_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mit_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: in user code:\n\n    <ipython-input-4-b7517a22445b>:36 distributed_train_step  *\n        per_replica_losses=strategy.run(train_step,args=(dataset_inputs,))\n    <ipython-input-4-b7517a22445b>:17 train_step  *\n        output=ae(inputs,training=False)\n    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/model.py:54 __call__  *\n        outputs = super().__call__(*args, **kwargs)\n    <ipython-input-3-371f5ca9fabc>:142 call  *\n        return super().call(batch,training=False)\n    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/autoencoder.py:59 call  *\n        features.update(self.decoder(features, training=training))\n    /usr/local/lib/python3.6/dist-packages/ddsp/training/models/model.py:54 __call__  *\n        outputs = super().__call__(*args, **kwargs)\n    <ipython-input-3-371f5ca9fabc>:76 call  *\n        x = self.rnn(x)\n    /usr/local/lib/python3.6/dist-packages/ddsp/training/nn.py:804 call  *\n        return self.rnn(x)\n    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py:659 __call__  **\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:444 call\n        inputs, initial_state, training, mask, row_lengths)\n    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:493 _defun_gru_call\n        'kernel': _read_variable_value(self.cell.kernel),\n    /usr/local/lib/python3.6/dist-packages/keras/layers/recurrent_v2.py:1759 _read_variable_value\n        return v.read_value()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/values.py:763 read_value\n        with ds_context.enter_or_assert_strategy(self._distribute_strategy):\n    /usr/lib/python3.6/contextlib.py:81 __enter__\n        return next(self.gen)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py:334 enter_or_assert_strategy\n        _assert_strategy(strategy)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py:367 _assert_strategy\n        (current_strategy, strategy))\n\n    RuntimeError: Mixing different tf.distribute.Strategy objects: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f18142b26d8> is not <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f19a956bd68>\n"
     ]
    }
   ],
   "source": [
    "## training loop with adam\n",
    "\n",
    "\n",
    "checkpoint_path=f\"artefacts/ae_v3_checkpoint_family_{INSTRUMENT_FAMILY}\"\n",
    "try:\n",
    "    print(\"loading checkpoint\")\n",
    "    ae.load_weights(checkpoint_path)\n",
    "except:\n",
    "    print(\"couldn't load checkpoint\")\n",
    "    pass\n",
    "e=0\n",
    "\n",
    "while True:\n",
    "  batch_counter=0\n",
    "  epoch_loss=0   \n",
    "  for batch in batched_dist_trn_dataset:\n",
    "        it_loss=distributed_train_step(batch)\n",
    "        epoch_loss+=it_loss\n",
    "        if batch_counter % 10==0:\n",
    "            print(f\"batch nr {batch_counter}, loss: {it_loss.numpy()}\")\n",
    "\n",
    "        batch_counter+=1\n",
    "  \n",
    "\n",
    "  plotlosses.update({'loss': epoch_loss/batch_counter,})\n",
    "\n",
    "  plotlosses.send()\n",
    "\n",
    "  print(f\"summary nr: {e}\")\n",
    "\n",
    "\n",
    "  #play(tf.reshape(output[\"audio\"],(-1)))\n",
    "  #play(tf.reshape(output['audio_synth'],(-1)))\n",
    "  #play(tf.reshape(output['add'][\"signal\"],(-1))) \n",
    "    \n",
    "  #plt.plot(output[\"ir\"][0])\n",
    "  #plt.show()\n",
    "    \n",
    "  ae.save_weights(checkpoint_path)\n",
    "\n",
    "  e+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(tf.reshape(batch[\"audio\"],(-1)))\n",
    "play(tf.reshape(output['add']['signal'],(-1))) \n",
    "play(tf.reshape(output['ir'],(-1))) \n",
    "play(tf.reshape(output['audio_synth'],(-1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pydash\n",
    "\n",
    "## validation \n",
    "\n",
    "val_dataset=list(val_dataset)\n",
    "\n",
    "VAL_LR=5e-3\n",
    "\n",
    "# order by velocity\n",
    "val_dataset=pydash.collections.sort_by(val_dataset,lambda x: x[\"velocity\"].numpy())\n",
    "\n",
    "#order by pitch\n",
    "val_dataset=pydash.collections.sort_by(val_dataset,lambda x: x[\"pitch\"].numpy())\n",
    "\n",
    "# group by instrument id\n",
    "val_dataset_by_instrument=pydash.collections.group_by(list(val_dataset),lambda x: str(x[\"instrument\"].numpy())+\" \"+str(x[\"velocity\"].numpy()))\n",
    "\n",
    "fit_iterations=100\n",
    "\n",
    "def rf2cf(row_form):\n",
    "    return {k:[s[k] for s in row_form] for k in row_form[0].keys()}\n",
    "    \n",
    "DEMO_NOTE_SAMPLES=int(0.2*SAMPLE_RATE)\n",
    "\n",
    "for instrument_set in val_dataset_by_instrument.values():    \n",
    "\n",
    "    val_optimizer = tf.keras.optimizers.Adam(learning_rate=VAL_LR)\n",
    "\n",
    "    # fit an embedding to highest and lowest note\n",
    "    \n",
    "    #fit_data=[instrument_set[int(len(instrument_set)/2)]]\n",
    "    \n",
    "    fit_data=[instrument_set[0],instrument_set[int(len(instrument_set)/2)],instrument_set[-1]]\n",
    "    \n",
    "    N_FIT_SAMPLES=len(fit_data)\n",
    "    \n",
    "    #convert to column form\n",
    "    fit_data = rf2cf(fit_data)\n",
    "        \n",
    "    fit_batch= next(iter(tf.data.Dataset.from_tensor_slices(fit_data).batch(N_FIT_SAMPLES)))\n",
    "    \n",
    "    fit_z=tf.Variable(tf.random.normal([1,INSTRUMENT_EMBEDDING_SIZE]))\n",
    "    fit_ir=tf.Variable(tf.concat([tf.zeros([1,1]),tf.zeros([1,IR_SIZE-1])],axis=-1))\n",
    "    \n",
    "    for i in range(fit_iterations):\n",
    "     \n",
    "        with tf.GradientTape() as tape:\n",
    "          fit_batch[\"z\"]=tf.tile(tf.tanh(fit_z),[N_FIT_SAMPLES,1])\n",
    "          fit_batch[\"ir\"]=tf.tile(tf.tanh(fit_ir),[N_FIT_SAMPLES,1])\n",
    "            \n",
    "          output=ae(fit_batch,training=False)\n",
    "\n",
    "          loss_value=spectral_loss(fit_batch[\"audio\"],output['audio_synth'])\n",
    "\n",
    "          gradients = tape.gradient(loss_value, [fit_z,fit_ir])\n",
    "          gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "            \n",
    "          print(loss_value)\n",
    "        \n",
    "        val_optimizer.apply_gradients(zip(gradients, [fit_z,fit_ir]))\n",
    "        \n",
    "    print(loss_value)\n",
    "           \n",
    "    play(tf.reshape(fit_batch[\"audio\"],(-1)))\n",
    "    play(tf.reshape(output['audio_synth'],(-1)))\n",
    "    play(tf.reshape(output['add'][\"signal\"],(-1)))\n",
    "    play(tf.reshape(fit_ir,(-1)))\n",
    "        \n",
    "    N_SCALE_SAMPLES=len(instrument_set)\n",
    "        \n",
    "    scale_data = rf2cf(instrument_set) \n",
    "    scale_batch= next(iter(tf.data.Dataset.from_tensor_slices(scale_data).batch(N_SCALE_SAMPLES)))\n",
    "    \n",
    "    play(tf.reshape(scale_batch[\"audio\"][:,:DEMO_NOTE_SAMPLES],(-1)))\n",
    "    \n",
    "    scale_batch[\"z\"] = tf.tile(tf.tanh(fit_z),[N_SCALE_SAMPLES,1])\n",
    "    scale_batch[\"ir\"] = tf.tile(fit_ir,[N_SCALE_SAMPLES,1])\n",
    "        \n",
    "    scale_batch_output=ae(scale_batch,training=False)\n",
    "    \n",
    "    play(tf.reshape(scale_batch_output['audio_synth'][:,:DEMO_NOTE_SAMPLES],(-1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sgd training loop\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "checkpoint_path=f\"artefacts/ae_v2_checkpoint_family_{INSTRUMENT_FAMILY}\"\n",
    "try:\n",
    "    print(\"loading checkpoint\")\n",
    "    ae.load_weights(checkpoint_path)\n",
    "except:\n",
    "    print(\"couldn't load checkpoint\")\n",
    "    pass\n",
    "e=0\n",
    "\n",
    "\n",
    "#tf.debugging.experimental.enable_dump_debug_info(\"logdir\", tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "while True:\n",
    "  batch_counter=0\n",
    "  epoch_loss=0   \n",
    "  for batch in batched_trn_dataset:\n",
    "    a = time.time()\n",
    "\n",
    "    batch_z=[]\n",
    "    batch_ir=[]\n",
    "\n",
    "    # ptr\n",
    "    for sample_index in range(batch[\"instrument\"].shape[0]):\n",
    "      instrument_id=batch[\"instrument\"][sample_index].numpy()\n",
    "      if instrument_id not in instrument_data:\n",
    "        instrument_data[instrument_id]={}\n",
    "        instrument_data[instrument_id][\"z\"]=tf.random.normal([INSTRUMENT_EMBEDDING_SIZE]).numpy()\n",
    "        instrument_data[instrument_id][\"ir\"]=tf.random.normal([IR_SIZE],mean=0,stddev=1e-6).numpy()\n",
    "\n",
    "      batch_z.append(instrument_data[instrument_id][\"z\"])\n",
    "      batch_ir.append(instrument_data[instrument_id][\"ir\"])   \n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "      batch_z_tf = tf.Variable(tf.stack(batch_z))\n",
    "      batch_ir_tf = tf.Variable(tf.stack(batch_ir)) \n",
    "\n",
    "      batch[\"z\"]=tf.tanh(batch_z_tf)\n",
    "      batch[\"ir\"]=tf.tanh(batch_ir_tf)\n",
    "\n",
    "      output=ae(batch,training=False)\n",
    "\n",
    "      loss_value=spectral_loss(batch[\"audio\"],output['audio_synth'])\n",
    "\n",
    "      gradients = tape.gradient(loss_value, [batch_z_tf,batch_ir_tf,*ae.trainable_variables])\n",
    "      gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "\n",
    "      epoch_loss+=loss_value.numpy()\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, [batch_z_tf,batch_ir_tf,*ae.trainable_variables]))\n",
    "\n",
    "    for sample_index in range(batch[\"instrument\"].shape[0]):\n",
    "      # TODO: average instrument embeddings per instrument\n",
    "      instrument_data[instrument_id][\"z\"]=batch_z_tf[sample_index].numpy()\n",
    "      instrument_data[instrument_id][\"ir\"]=batch_ir_tf[sample_index].numpy()\n",
    "\n",
    "    #print(f\"batch took {time.time()-a} s\")\n",
    "        \n",
    "    batch_counter+=1\n",
    "    \n",
    "  plotlosses.update({\n",
    "    'loss': epoch_loss/batch_counter,\n",
    "  })\n",
    "\n",
    "  plotlosses.send()\n",
    "\n",
    "  print(f\"summary nr: {e}\")\n",
    "\n",
    "  print(loss_value)\n",
    "  play(tf.reshape(batch[\"audio\"],(-1)))\n",
    "  play(tf.reshape(output['audio_synth'],(-1)))\n",
    "    \n",
    "  plt.plot(batch[\"ir\"][0])\n",
    "\n",
    "  ae.save_weights(checkpoint_path)\n",
    "\n",
    "  e+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "slow instrument cloning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
