{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3kBReFZb1eKk"
   },
   "outputs": [],
   "source": [
    "# imports and utils\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import ddsp.training\n",
    "_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "from IPython.display import Audio, display\n",
    "from livelossplot import PlotLosses\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import data\n",
    "\n",
    "# define constants\n",
    "N_SAMPLES=16000*4\n",
    "SAMPLE_RATE=16000\n",
    "SEED=1\n",
    "\n",
    "tf.random.set_seed(\n",
    "    SEED\n",
    ")\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "# define some utilis\n",
    "def play(audio):\n",
    "  display(Audio(audio,rate=SAMPLE_RATE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "USE_NSYNTH=False\n",
    "if USE_NSYNTH:\n",
    "    \n",
    "    class CustomNSynthTfds(ddsp.training.data.TfdsProvider):\n",
    "      \"\"\"Parses features in the TFDS NSynth dataset.\n",
    "      Unlike the default Nsynth data provider, this class keeps the the nsynth instrument metadata.\n",
    "\n",
    "      If running on Cloud, it is recommended you set `data_dir` to\n",
    "      'gs://tfds-data/datasets' to avoid unnecessary downloads.\n",
    "      \"\"\"\n",
    "\n",
    "      def __init__(self,\n",
    "                   name='nsynth/gansynth_subset.f0_and_loudness:2.3.3',\n",
    "                   split='train',\n",
    "                   data_dir='gs://tfds-data/datasets',\n",
    "                   sample_rate=16000,\n",
    "                   frame_rate=250,\n",
    "                   include_note_labels=True):\n",
    "        \"\"\"TfdsProvider constructor.\n",
    "        Args:\n",
    "          name: TFDS dataset name (with optional config and version).\n",
    "          split: Dataset split to use of the TFDS dataset.\n",
    "          data_dir: The directory to read the prepared NSynth dataset from. Defaults\n",
    "            to the public TFDS GCS bucket.\n",
    "          sample_rate: Sample rate of audio in the dataset.\n",
    "          frame_rate: Frame rate of features in the dataset.\n",
    "          include_note_labels: Return dataset without note-level labels\n",
    "            (pitch, instrument).\n",
    "        \"\"\"\n",
    "        self._include_note_labels = include_note_labels\n",
    "\n",
    "        super().__init__(name, split, data_dir, sample_rate, frame_rate)\n",
    "\n",
    "      def get_dataset(self, shuffle=True):\n",
    "        \"\"\"Returns dataset with slight restructuring of feature dictionary.\"\"\"\n",
    "        def preprocess_ex(ex):\n",
    "          ex_out = {\n",
    "              'audio':\n",
    "                  ex['audio'],\n",
    "              'f0_hz':\n",
    "                  ex['f0']['hz'],\n",
    "              'f0_confidence':\n",
    "                  ex['f0']['confidence'],\n",
    "              'loudness_db':\n",
    "                  ex['loudness']['db'],\n",
    "          }\n",
    "          if self._include_note_labels:\n",
    "            ex_out.update({\n",
    "                'pitch':\n",
    "                    ex['pitch'],\n",
    "                'velocity':\n",
    "                    ex['velocity'],\n",
    "                'instrument_source':\n",
    "                    ex['instrument']['source'],\n",
    "                'instrument_family':\n",
    "                    ex['instrument']['family'],\n",
    "                'instrument':\n",
    "                    ex['instrument']['label'],\n",
    "            })\n",
    "          return ex_out\n",
    "\n",
    "        dataset = super().get_dataset(shuffle)\n",
    "        dataset = dataset.map(preprocess_ex, num_parallel_calls=_AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    tfds.load(\"nsynth/gansynth_subset.f0_and_loudness\",split=\"train\", try_gcs=False,download=True) \n",
    "    trn_data_provider = CustomNSynthTfds(data_dir=\"/root/tensorflow_datasets/\",split=\"train\")\n",
    "\n",
    "    tfds.load(\"nsynth/gansynth_subset.f0_and_loudness\",split=\"valid\", try_gcs=False,download=True) \n",
    "    val_data_provider = CustomNSynthTfds(data_dir=\"/root/tensorflow_datasets/\",split=\"valid\")\n",
    "    \n",
    "    # take a batch of flute sounds\n",
    "    #dataset = data_provider.get_dataset()\n",
    "\n",
    "    # take only acoustic sounds\n",
    "    #dataset=dataset.filter(lambda x: x[\"instrument_source\"]==0)\n",
    "\n",
    "    # take only flute sounds\n",
    "    #dataset=dataset.filter(lambda x: x[\"instrument_family\"]==2)\n",
    "\n",
    "    # flutes\n",
    "    # 2965 samples\n",
    "    # 36 instruments\n",
    "    # 5 velocities \n",
    "    # 61 pitches\n",
    "\n",
    "    #test_batch=next(iter(dataset.batch(4))) \n",
    "\n",
    "    #play(tf.reshape(test_batch[\"audio\"],(-1)))\n",
    "\n",
    "    # TODO: CLEAN UP DATASET. REMOVE WHERE CREPE IS UNCERTAIN.\n",
    "\n",
    "    def crepe_is_certain(x):\n",
    "        is_playing = tf.cast(x[\"loudness_db\"]>-100.0,dtype=tf.float32)\n",
    "        average_certainty=tf.reduce_sum(x[\"f0_confidence\"]*is_playing)/tf.reduce_sum(is_playing)\n",
    "        return average_certainty\n",
    "\n",
    "    '''\n",
    "    for s in range(1):\n",
    "\n",
    "        print(\"###\")\n",
    "\n",
    "        sample = next(iter(dataset))\n",
    "        play(sample[\"audio\"])\n",
    "\n",
    "        print(crepe_is_certain(sample))\n",
    "\n",
    "        plt.plot(sample[\"loudness_db\"])\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(sample[\"f0_hz\"])\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(sample[\"f0_confidence\"])\n",
    "        plt.show()\n",
    "\n",
    "    '''\n",
    "\n",
    "    INSTRUMENT_FAMILY=2\n",
    "\n",
    "    def preprocess_dataset(dataset):\n",
    "        if INSTRUMENT_FAMILY!=\"all\":\n",
    "            dataset=dataset.filter(lambda x: x[\"instrument_family\"]==INSTRUMENT_FAMILY)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    trn_dataset = preprocess_dataset(trn_data_provider.get_dataset())\n",
    "    val_dataset = preprocess_dataset(val_data_provider.get_dataset())\n",
    "\n",
    "    # take only flute sounds\n",
    "\n",
    "\n",
    "else:\n",
    "    INSTRUMENT_FAMILY=\"solos-violin-clean\"\n",
    "    \n",
    "    trn_data_provider=data.MultiTFRecordProvider(f\"datasets/{INSTRUMENT_FAMILY}/tfr/trn/*\")\n",
    "    val_data_provider=data.MultiTFRecordProvider(f\"datasets/{INSTRUMENT_FAMILY}/tfr/val/*\")\n",
    "    \n",
    "    trn_dataset= trn_data_provider.get_dataset()\n",
    "    val_dataset=val_data_provider.get_dataset()\n",
    "    \n",
    "    def preprocess_dataset(dataset):\n",
    "        dataset=dataset.filter(lambda x: tf.math.count_nonzero(x[\"audio\"])>0)\n",
    "        return dataset\n",
    "    \n",
    "    trn_dataset = preprocess_dataset(trn_dataset)\n",
    "    val_dataset = preprocess_dataset(val_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Kj83Q3YrDEeT"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "N_NOISE_MAGNITUDES=64\n",
    "N_HARMONICS=64\n",
    "\n",
    "\n",
    "class CustomReverb(ddsp.processors.Processor):\n",
    "\n",
    "    def __init__(self,name='reverb'):\n",
    "        \"\"\"Takes neural network outputs directly as the impulse response.\n",
    "        Args:\n",
    "          trainable: Learn the impulse_response as a single variable for the entire\n",
    "            dataset.\n",
    "          reverb_length: Length of the impulse response. Only used if\n",
    "            trainable=True.\n",
    "          add_dry: Add dry signal to reverberated signal on output.\n",
    "          name: Name of processor module.\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "    \n",
    "    def get_controls(self, audio, ir=None):\n",
    "        \"\"\"Convert decoder outputs into ir response.\n",
    "        Args:\n",
    "          audio: Dry audio. 2-D Tensor of shape [batch, n_samples].\n",
    "          ir: 3-D Tensor of shape [batch, ir_size, 1] or 2D Tensor of shape\n",
    "            [batch, ir_size].\n",
    "        Returns:\n",
    "          controls: Dictionary of effect controls.\n",
    "        \"\"\"\n",
    "        return {'audio': audio, 'ir': ir}\n",
    "\n",
    "    def get_signal(self, audio, ir):\n",
    "        \"\"\"Apply impulse response.\n",
    "        Args:\n",
    "          audio: Dry audio, 2-D Tensor of shape [batch, n_samples].\n",
    "          ir: 3-D Tensor of shape [batch, ir_size, 1] or 2D Tensor of shape\n",
    "            [batch, ir_size].\n",
    "        Returns:\n",
    "          tensor of shape [batch, n_samples]\n",
    "        \"\"\"\n",
    "        wet = ddsp.core.fft_convolve(audio, ir, padding='same', delay_compensation=0)\n",
    "        return wet\n",
    "\n",
    "class LGD(ddsp.training.models.Model):\n",
    "\n",
    "    def __init__(self, n_out,  rnn_channels=256, rnn_type='gru', ch=512, layers_per_stack=0, name=None):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        def stack():\n",
    "            return ddsp.training.nn.FcStack(ch, layers_per_stack)\n",
    "\n",
    "        self.input_keys = [\"f0_hz\", \"ld_scaled\"]\n",
    "\n",
    "        self.n_out = n_out\n",
    "        self.input_stacks = [stack() for k in self.input_keys]\n",
    "\n",
    "        self.rnn = ddsp.training.nn.Rnn(rnn_channels, rnn_type)\n",
    "        self.out_stack = stack()\n",
    "        self.dense_out = ddsp.training.nn.Fc(self.n_out)\n",
    "\n",
    "    def call(self, conditioning):\n",
    "\n",
    "        instrument_representation = conditioning[\"z\"]\n",
    "\n",
    "        feature_len = conditioning[\"f0_scaled\"].shape[1]\n",
    "\n",
    "        instrument_representation = tf.repeat(\n",
    "            instrument_representation[:, None, ...], feature_len, axis=1)\n",
    "\n",
    "        inputs = [conditioning[k] for k in self.input_keys]\n",
    "\n",
    "        inputs = [stack(x) for stack, x in zip(self.input_stacks, inputs)]\n",
    "\n",
    "        x = tf.concat(inputs, axis=(-1))\n",
    "        x = tf.concat([x, instrument_representation], axis=2)\n",
    "        x = self.rnn(x)\n",
    "        x = tf.concat((inputs + [x]), axis=(-1))\n",
    "        x = self.out_stack(x)\n",
    "        out = self.dense_out(x)\n",
    "        \n",
    "        \n",
    "        loudness=out[:,:,-1:]\n",
    "        noise_magnitudes = out[:,:,:N_NOISE_MAGNITUDES]\n",
    "        harmonic_distribution = out[:,:,-N_HARMONICS:-1]\n",
    "            \n",
    "        return {\"amps\":loudness,\"harmonic_distribution\":harmonic_distribution,\"magnitudes\":noise_magnitudes}\n",
    "    \n",
    "preprocessor=ddsp.training.preprocessing.F0LoudnessPreprocessor()\n",
    "decoder = LGD(n_out=N_NOISE_MAGNITUDES+N_HARMONICS+1)\n",
    "harmonic_synth = ddsp.synths.Harmonic(\n",
    "    n_samples=N_SAMPLES, sample_rate=SAMPLE_RATE, name='harmonic')\n",
    "\n",
    "filtered_noise = ddsp.synths.FilteredNoise(\n",
    "    n_samples=N_SAMPLES, window_size=0, initial_bias=-10.0, name='noise')\n",
    "reverb = ddsp.effects.Reverb(name=\"reverb\",trainable=False)\n",
    "add = ddsp.processors.Add(name='add')\n",
    "\n",
    "dag = [\n",
    "  (harmonic_synth, ['amps', 'harmonic_distribution', 'f0_hz']),\n",
    "  (filtered_noise, ['magnitudes']),\n",
    "  (add, ['harmonic/signal', 'noise/signal']),\n",
    "  (reverb, [\"add/signal\",\"ir\"])\n",
    "]\n",
    "\n",
    "processor_group=ddsp.processors.ProcessorGroup(dag=dag)\n",
    "\n",
    "spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
    "                                              mag_weight=1.0,\n",
    "                                              logmag_weight=1.0)\n",
    "\n",
    "\n",
    "class MultiInstrumentAutoencoder(ddsp.training.models.autoencoder.Autoencoder):\n",
    "    def __init__(self,\n",
    "               preprocessor=None,\n",
    "               encoder=None,\n",
    "               decoder=None,\n",
    "               processor_group=None,\n",
    "               losses=None,\n",
    "               n_instruments=None,\n",
    "               z_size=None,\n",
    "               ir_size=None,\n",
    "               **kwargs):\n",
    "        super().__init__(preprocessor,encoder,decoder,processor_group,losses,**kwargs)\n",
    "        \n",
    "        self.n_instruments=n_instruments\n",
    "        self.instrument_z = tf.Variable(tf.random.normal([n_instruments,z_size]))\n",
    "        self.instrument_ir = tf.Variable(tf.concat([tf.ones([n_instruments,1]),tf.zeros([n_instruments,ir_size-1])],axis=-1))\n",
    "        self.instrument_id2idx={}\n",
    "        \n",
    "    def call(self, batch, training=True):\n",
    "        instrument_idxs=[]\n",
    " \n",
    "        for sample_index in range(batch[\"instrument\"].shape[0]):\n",
    "          instrument_id=str(batch[\"instrument\"][sample_index])\n",
    "          if instrument_id not in self.instrument_id2idx:\n",
    "              self.instrument_id2idx[instrument_id]=len(self.instrument_id2idx.keys())\n",
    "          instrument_idxs.append(int(self.instrument_id2idx[instrument_id]))\n",
    "  \n",
    "        with tf.GradientTape() as tape:\n",
    "          batch[\"z\"]=tf.tanh(tf.gather(self.instrument_z,instrument_idxs))\n",
    "          batch[\"ir\"]=tf.tanh(tf.gather(self.instrument_ir,instrument_idxs))     \n",
    "        return super().call(batch,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wJUeq9Kmwbga",
    "outputId": "d27f1547-a061-4bf7-d3d6-f5715199fb3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n",
      "loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "Z_SIZE=256\n",
    "\n",
    "N_INSTRUMENTS=1050\n",
    "\n",
    "IR_SIZE=int(SAMPLE_RATE*1.0)\n",
    "\n",
    "checkpoint_path=f\"artefacts/ae_v3_checkpoint_family_{INSTRUMENT_FAMILY}\"\n",
    "\n",
    "plotlosses = PlotLosses()\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "\n",
    "def train_step(inputs):\n",
    "     \n",
    "    with tf.GradientTape() as tape:\n",
    "    \n",
    "        a = time.time()\n",
    "\n",
    "        output=ae(inputs,training=False)\n",
    "\n",
    "        loss_value=spectral_loss(inputs[\"audio\"],output['audio_synth'])\n",
    "\n",
    "        gradients = tape.gradient(loss_value, [*ae.trainable_variables])\n",
    "\n",
    "        #grad_is_nan=False\n",
    "        #for g in gradients:\n",
    "        #    grad_is_nan=grad_is_nan or tf.math.reduce_any(tf.math.is_nan(g))\n",
    "        \n",
    "\n",
    "        # if not grad_is_nan:\n",
    "        optimizer.apply_gradients(zip(gradients, [*ae.trainable_variables]))\n",
    "        \n",
    "    return loss_value\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses=strategy.run(train_step,args=(dataset_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM,per_replica_losses,axis=None)\n",
    "\n",
    "with strategy.scope():\n",
    "    ae = MultiInstrumentAutoencoder(preprocessor=preprocessor,decoder=decoder,processor_group=processor_group,n_instruments=N_INSTRUMENTS,z_size=Z_SIZE,ir_size=IR_SIZE) \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        print(\"loading checkpoint\")\n",
    "        ae.load_weights(checkpoint_path)\n",
    "    except:\n",
    "        print(\"couldn't load checkpoint\")\n",
    "        pass\n",
    "\n",
    "\n",
    "BATCH_SIZE=16\n",
    "\n",
    "batched_trn_dataset= trn_dataset.shuffle(10000).batch(BATCH_SIZE*len(tf.config.list_physical_devices('GPU')),drop_remainder=True)\n",
    "batched_dist_trn_dataset = strategy.experimental_distribute_dataset(batched_trn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\tloss             \t (min:   68.296, max:   70.140, cur:   68.379)\n",
      "summary nr: 8\n",
      "batch nr 0, loss: 67.44937133789062\n",
      "batch nr 10, loss: 69.6278076171875\n",
      "batch nr 20, loss: 67.8044204711914\n",
      "batch nr 30, loss: 69.82920837402344\n"
     ]
    }
   ],
   "source": [
    "## training loop with adam\n",
    "\n",
    "\n",
    "e=0\n",
    "\n",
    "while True:\n",
    "  batch_counter=0\n",
    "  epoch_loss=0   \n",
    "  for batch in batched_dist_trn_dataset:\n",
    "        it_loss=distributed_train_step(batch)\n",
    "        epoch_loss+=it_loss\n",
    "        if batch_counter % 10==0:\n",
    "            print(f\"batch nr {batch_counter}, loss: {it_loss.numpy()}\")\n",
    "\n",
    "        batch_counter+=1\n",
    "  \n",
    "\n",
    "  plotlosses.update({'loss': epoch_loss/batch_counter,})\n",
    "\n",
    "  plotlosses.send()\n",
    "\n",
    "  print(f\"summary nr: {e}\")\n",
    "\n",
    "\n",
    "  #play(tf.reshape(output[\"audio\"],(-1)))\n",
    "  #play(tf.reshape(output['audio_synth'],(-1)))\n",
    "  #play(tf.reshape(output['add'][\"signal\"],(-1))) \n",
    "    \n",
    "  #plt.plot(output[\"ir\"][0])\n",
    "  #plt.show()\n",
    "    \n",
    "  ae.save_weights(checkpoint_path)\n",
    "\n",
    "  e+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(tf.reshape(batch[\"audio\"],(-1)))\n",
    "play(tf.reshape(output['add']['signal'],(-1))) \n",
    "play(tf.reshape(output['ir'],(-1))) \n",
    "play(tf.reshape(output['audio_synth'],(-1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pydash\n",
    "\n",
    "## validation \n",
    "\n",
    "val_dataset=list(val_dataset)\n",
    "\n",
    "VAL_LR=5e-3\n",
    "\n",
    "# order by velocity\n",
    "val_dataset=pydash.collections.sort_by(val_dataset,lambda x: x[\"velocity\"].numpy())\n",
    "\n",
    "#order by pitch\n",
    "val_dataset=pydash.collections.sort_by(val_dataset,lambda x: x[\"pitch\"].numpy())\n",
    "\n",
    "# group by instrument id\n",
    "val_dataset_by_instrument=pydash.collections.group_by(list(val_dataset),lambda x: str(x[\"instrument\"].numpy())+\" \"+str(x[\"velocity\"].numpy()))\n",
    "\n",
    "fit_iterations=100\n",
    "\n",
    "def rf2cf(row_form):\n",
    "    return {k:[s[k] for s in row_form] for k in row_form[0].keys()}\n",
    "    \n",
    "DEMO_NOTE_SAMPLES=int(0.2*SAMPLE_RATE)\n",
    "\n",
    "for instrument_set in val_dataset_by_instrument.values():    \n",
    "\n",
    "    val_optimizer = tf.keras.optimizers.Adam(learning_rate=VAL_LR)\n",
    "\n",
    "    # fit an embedding to highest and lowest note\n",
    "    \n",
    "    #fit_data=[instrument_set[int(len(instrument_set)/2)]]\n",
    "    \n",
    "    fit_data=[instrument_set[0],instrument_set[int(len(instrument_set)/2)],instrument_set[-1]]\n",
    "    \n",
    "    N_FIT_SAMPLES=len(fit_data)\n",
    "    \n",
    "    #convert to column form\n",
    "    fit_data = rf2cf(fit_data)\n",
    "        \n",
    "    fit_batch= next(iter(tf.data.Dataset.from_tensor_slices(fit_data).batch(N_FIT_SAMPLES)))\n",
    "    \n",
    "    fit_z=tf.Variable(tf.random.normal([1,INSTRUMENT_EMBEDDING_SIZE]))\n",
    "    fit_ir=tf.Variable(tf.concat([tf.zeros([1,1]),tf.zeros([1,IR_SIZE-1])],axis=-1))\n",
    "    \n",
    "    for i in range(fit_iterations):\n",
    "     \n",
    "        with tf.GradientTape() as tape:\n",
    "          fit_batch[\"z\"]=tf.tile(tf.tanh(fit_z),[N_FIT_SAMPLES,1])\n",
    "          fit_batch[\"ir\"]=tf.tile(tf.tanh(fit_ir),[N_FIT_SAMPLES,1])\n",
    "            \n",
    "          output=ae(fit_batch,training=False)\n",
    "\n",
    "          loss_value=spectral_loss(fit_batch[\"audio\"],output['audio_synth'])\n",
    "\n",
    "          gradients = tape.gradient(loss_value, [fit_z,fit_ir])\n",
    "          gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "            \n",
    "          print(loss_value)\n",
    "        \n",
    "        val_optimizer.apply_gradients(zip(gradients, [fit_z,fit_ir]))\n",
    "        \n",
    "    print(loss_value)\n",
    "           \n",
    "    play(tf.reshape(fit_batch[\"audio\"],(-1)))\n",
    "    play(tf.reshape(output['audio_synth'],(-1)))\n",
    "    play(tf.reshape(output['add'][\"signal\"],(-1)))\n",
    "    play(tf.reshape(fit_ir,(-1)))\n",
    "        \n",
    "    N_SCALE_SAMPLES=len(instrument_set)\n",
    "        \n",
    "    scale_data = rf2cf(instrument_set) \n",
    "    scale_batch= next(iter(tf.data.Dataset.from_tensor_slices(scale_data).batch(N_SCALE_SAMPLES)))\n",
    "    \n",
    "    play(tf.reshape(scale_batch[\"audio\"][:,:DEMO_NOTE_SAMPLES],(-1)))\n",
    "    \n",
    "    scale_batch[\"z\"] = tf.tile(tf.tanh(fit_z),[N_SCALE_SAMPLES,1])\n",
    "    scale_batch[\"ir\"] = tf.tile(fit_ir,[N_SCALE_SAMPLES,1])\n",
    "        \n",
    "    scale_batch_output=ae(scale_batch,training=False)\n",
    "    \n",
    "    play(tf.reshape(scale_batch_output['audio_synth'][:,:DEMO_NOTE_SAMPLES],(-1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sgd training loop\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "checkpoint_path=f\"artefacts/ae_v2_checkpoint_family_{INSTRUMENT_FAMILY}\"\n",
    "try:\n",
    "    print(\"loading checkpoint\")\n",
    "    ae.load_weights(checkpoint_path)\n",
    "except:\n",
    "    print(\"couldn't load checkpoint\")\n",
    "    pass\n",
    "e=0\n",
    "\n",
    "\n",
    "#tf.debugging.experimental.enable_dump_debug_info(\"logdir\", tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "while True:\n",
    "  batch_counter=0\n",
    "  epoch_loss=0   \n",
    "  for batch in batched_trn_dataset:\n",
    "    a = time.time()\n",
    "\n",
    "    batch_z=[]\n",
    "    batch_ir=[]\n",
    "\n",
    "    # ptr\n",
    "    for sample_index in range(batch[\"instrument\"].shape[0]):\n",
    "      instrument_id=batch[\"instrument\"][sample_index].numpy()\n",
    "      if instrument_id not in instrument_data:\n",
    "        instrument_data[instrument_id]={}\n",
    "        instrument_data[instrument_id][\"z\"]=tf.random.normal([INSTRUMENT_EMBEDDING_SIZE]).numpy()\n",
    "        instrument_data[instrument_id][\"ir\"]=tf.random.normal([IR_SIZE],mean=0,stddev=1e-6).numpy()\n",
    "\n",
    "      batch_z.append(instrument_data[instrument_id][\"z\"])\n",
    "      batch_ir.append(instrument_data[instrument_id][\"ir\"])   \n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "      batch_z_tf = tf.Variable(tf.stack(batch_z))\n",
    "      batch_ir_tf = tf.Variable(tf.stack(batch_ir)) \n",
    "\n",
    "      batch[\"z\"]=tf.tanh(batch_z_tf)\n",
    "      batch[\"ir\"]=tf.tanh(batch_ir_tf)\n",
    "\n",
    "      output=ae(batch,training=False)\n",
    "\n",
    "      loss_value=spectral_loss(batch[\"audio\"],output['audio_synth'])\n",
    "\n",
    "      gradients = tape.gradient(loss_value, [batch_z_tf,batch_ir_tf,*ae.trainable_variables])\n",
    "      gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "\n",
    "      epoch_loss+=loss_value.numpy()\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, [batch_z_tf,batch_ir_tf,*ae.trainable_variables]))\n",
    "\n",
    "    for sample_index in range(batch[\"instrument\"].shape[0]):\n",
    "      # TODO: average instrument embeddings per instrument\n",
    "      instrument_data[instrument_id][\"z\"]=batch_z_tf[sample_index].numpy()\n",
    "      instrument_data[instrument_id][\"ir\"]=batch_ir_tf[sample_index].numpy()\n",
    "\n",
    "    #print(f\"batch took {time.time()-a} s\")\n",
    "        \n",
    "    batch_counter+=1\n",
    "    \n",
    "  plotlosses.update({\n",
    "    'loss': epoch_loss/batch_counter,\n",
    "  })\n",
    "\n",
    "  plotlosses.send()\n",
    "\n",
    "  print(f\"summary nr: {e}\")\n",
    "\n",
    "  print(loss_value)\n",
    "  play(tf.reshape(batch[\"audio\"],(-1)))\n",
    "  play(tf.reshape(output['audio_synth'],(-1)))\n",
    "    \n",
    "  plt.plot(batch[\"ir\"][0])\n",
    "\n",
    "  ae.save_weights(checkpoint_path)\n",
    "\n",
    "  e+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "slow instrument cloning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
